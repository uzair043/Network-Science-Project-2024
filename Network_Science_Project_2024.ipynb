{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45IN7-rTQW-S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# Loading the data\n",
    "election_data = pd.read_excel('wikiElec.ElecBs3.xls', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sl-_P1FSXYXx",
    "outputId": "2a4d1c7b-be81-4f8d-ad5d-33fdd226206b"
   },
   "outputs": [],
   "source": [
    "print(election_data.head())\n",
    "election_data.columns = ['Type', 'Value1', 'Value2', 'Value3', 'Value4']\n",
    "print(election_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5wopK87bXTv",
    "outputId": "4783f4bf-bb10-45d3-9e2f-bdecc939f5d2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Empty list to collect cleaned election data\n",
    "clean_data_list = []\n",
    "\n",
    "# Temporary dictionary to hold current election data\n",
    "current_election = {}\n",
    "\n",
    "# Iterating over each row in the dataset\n",
    "for index, row in election_data.iterrows():\n",
    "    if row['Type'] == 'E':\n",
    "        # Start of a new election block, saving previous block if it exists\n",
    "        if current_election:\n",
    "            clean_data_list.append(current_election)\n",
    "        current_election = {'ElectionSuccess': row['Value1']}\n",
    "    elif row['Type'] == 'T':\n",
    "        current_election['ClosingTime'] = pd.to_datetime(row['Value1'])\n",
    "    elif row['Type'] == 'U':\n",
    "        current_election['CandidateID'] = row['Value1']\n",
    "        current_election['CandidateName'] = row['Value2']\n",
    "    elif row['Type'] == 'N':\n",
    "        current_election['NominatorID'] = row['Value1']\n",
    "        current_election['NominatorName'] = row['Value2']\n",
    "    elif row['Type'] == 'V':\n",
    "        current_election.setdefault('Votes', []).append({\n",
    "            'VoteType': int(row['Value1']),\n",
    "            'VoterID': row['Value2'],\n",
    "            'VoteTime': pd.to_datetime(row['Value3']),\n",
    "            'VoterName': row['Value4']\n",
    "        })\n",
    "\n",
    "# Appending the last election block if it exists\n",
    "if current_election:\n",
    "    clean_data_list.append(current_election)\n",
    "\n",
    "clean_data = pd.DataFrame(clean_data_list)\n",
    "\n",
    "print(clean_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYMJcEakbstI",
    "outputId": "f3c2f124-cca5-4d79-8eb9-b7e81309227d"
   },
   "outputs": [],
   "source": [
    "# Creating a unique election identifier in the clean_data DataFrame\n",
    "clean_data['ElectionID'] = clean_data['CandidateID'].astype(str) + '_' + clean_data['ClosingTime'].dt.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "# 'ElectionID' as the index\n",
    "clean_data.set_index('ElectionID', inplace=True)\n",
    "\n",
    "print(clean_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBtxG6SeZVgA"
   },
   "outputs": [],
   "source": [
    "# Constructing a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Adding edges from the votes data with context of specific election instances\n",
    "for index, election in clean_data.iterrows():\n",
    "    candidate_node = f\"{election['CandidateID']}_{election['ClosingTime'].strftime('%Y%m%d%H%M%S')}\"\n",
    "    for vote in election['Votes']:\n",
    "        voter_node = f\"{vote['VoterID']}_{election['ClosingTime'].strftime('%Y%m%d%H%M%S')}\"\n",
    "        if vote['VoteType'] == 1:  # Assuming '1' indicates a supportive vote\n",
    "            G.add_edge(voter_node, candidate_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 914
    },
    "id": "SO3fIFBwNZ5u",
    "outputId": "9c261b04-d42b-4b62-8767-27300fb4a94a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'clean_data' is the DataFrame containing the RfA data\n",
    "# Flattening the Votes column to have a single row per vote\n",
    "\n",
    "rows = []\n",
    "for index, election in clean_data.iterrows():\n",
    "    candidate_id = election['CandidateID']\n",
    "    for vote in election['Votes']:\n",
    "        if vote['VoteType'] == 1:  # Only supportive votes\n",
    "            rows.append({\n",
    "                'VoterID': vote['VoterID'],\n",
    "                'CandidateID': candidate_id\n",
    "            })\n",
    "\n",
    "# Creating a new DataFrame from the flattened data\n",
    "votes_df = pd.DataFrame(rows)\n",
    "\n",
    "# Creating a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Adding edges based on the supportive votes\n",
    "for index, row in votes_df.iterrows():\n",
    "    voter_node = str(row['VoterID'])\n",
    "    candidate_node = str(row['CandidateID'])\n",
    "    G.add_edge(voter_node, candidate_node)\n",
    "\n",
    "print(\"Nodes:\", G.number_of_nodes())\n",
    "print(\"Edges:\", G.number_of_edges())\n",
    "\n",
    "# Visualizing the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_size=500, node_color=\"skyblue\", font_size=8, font_weight=\"bold\", edge_color=\"gray\")\n",
    "plt.title(\"Wikipedia RfA Voting Network\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "id": "-hDYoLytPzDY",
    "outputId": "7cb64dd1-f4ec-4047-8837-2c75ddde720e"
   },
   "outputs": [],
   "source": [
    "# Selecting a random subset of 100 nodes\n",
    "random_nodes = random.sample(G.nodes(), 100)\n",
    "\n",
    "# Creating a subgraph with these nodes\n",
    "subgraph = G.subgraph(random_nodes)\n",
    "\n",
    "# Visualizing the subgraph\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(subgraph)\n",
    "nx.draw(subgraph, pos, with_labels=True, node_size=500, node_color=\"skyblue\", font_size=8, font_weight=\"bold\", edge_color=\"gray\")\n",
    "plt.title(\"Subset of 100 Nodes from the Wikipedia RfA Voting Network\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Arh4G6PdZfCi"
   },
   "outputs": [],
   "source": [
    "# Calculation of centrality measures\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G, k=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyzN3g1SR_Gk",
    "outputId": "5a7d1271-0dad-42f4-a818-7f9fa539675b"
   },
   "outputs": [],
   "source": [
    "# DataFrame for centrality measures\n",
    "centrality_df = pd.DataFrame({\n",
    "    'Node': list(G.nodes()),\n",
    "    'DegreeCentrality': [degree_centrality[node] for node in G.nodes()],\n",
    "    'ClosenessCentrality': [closeness_centrality[node] for node in G.nodes()],\n",
    "    'BetweennessCentrality': [betweenness_centrality[node] for node in G.nodes()]\n",
    "})\n",
    "\n",
    "# Extracting ElectionSuccess by mapping from the unique 'ElectionID'\n",
    "def map_election_success(node):\n",
    "    if node in clean_data['CandidateID'].astype(str).values:\n",
    "        return clean_data.loc[clean_data['CandidateID'].astype(str) == node, 'ElectionSuccess'].values[0]\n",
    "    return None\n",
    "\n",
    "centrality_df['ElectionSuccess'] = centrality_df['Node'].apply(map_election_success)\n",
    "\n",
    "# Filtering out nodes with no ElectionSuccess information\n",
    "centrality_df = centrality_df.dropna(subset=['ElectionSuccess'])\n",
    "\n",
    "# Correlation analysis\n",
    "degree_corr, _ = pearsonr(centrality_df['DegreeCentrality'], centrality_df['ElectionSuccess'])\n",
    "closeness_corr, _ = pearsonr(centrality_df['ClosenessCentrality'], centrality_df['ElectionSuccess'])\n",
    "betweenness_corr, _ = pearsonr(centrality_df['BetweennessCentrality'], centrality_df['ElectionSuccess'])\n",
    "\n",
    "print(f\"Correlation between Degree Centrality and Election Success: {degree_corr:.3f}\")\n",
    "print(f\"Correlation between Closeness Centrality and Election Success: {closeness_corr:.3f}\")\n",
    "print(f\"Correlation between Betweenness Centrality and Election Success: {betweenness_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QQjvThbvpw8"
   },
   "source": [
    "4. Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juv330TmTDJG",
    "outputId": "448e3645-0314-45ef-f515-2abdcf9b75bc"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Calculating the activity level of each voter\n",
    "voter_activity = {node: G.out_degree(node) for node in G.nodes()}\n",
    "\n",
    "# Dictionary to store centrality and activity data for each election\n",
    "election_centralities = {}\n",
    "\n",
    "for index, election in clean_data.iterrows():\n",
    "    candidate_id = str(election['CandidateID'])\n",
    "    centrality_measures = {\n",
    "        'degree': [],\n",
    "        'closeness': [],\n",
    "        'betweenness': [],\n",
    "        'activity': []\n",
    "    }\n",
    "\n",
    "    for vote in election['Votes']:\n",
    "        if vote['VoteType'] == 1:  # Assuming '1' indicates a supportive vote\n",
    "            voter_node = str(vote['VoterID'])\n",
    "            centrality_measures['degree'].append(degree_centrality.get(voter_node, 0))\n",
    "            centrality_measures['closeness'].append(closeness_centrality.get(voter_node, 0))\n",
    "            centrality_measures['betweenness'].append(betweenness_centrality.get(voter_node, 0))\n",
    "            centrality_measures['activity'].append(voter_activity.get(voter_node, 0))  # Append activity level\n",
    "\n",
    "    # Calculating average centralities and storing them with election success and average activity\n",
    "    election_centralities[candidate_id] = {\n",
    "        'avg_degree': sum(centrality_measures['degree']) / len(centrality_measures['degree']) if centrality_measures['degree'] else 0,\n",
    "        'avg_closeness': sum(centrality_measures['closeness']) / len(centrality_measures['closeness']) if centrality_measures['closeness'] else 0,\n",
    "        'avg_betweenness': sum(centrality_measures['betweenness']) / len(centrality_measures['betweenness']) if centrality_measures['betweenness'] else 0,\n",
    "        'avg_activity': sum(centrality_measures['activity']) / len(centrality_measures['activity']) if centrality_measures['activity'] else 0,  # Average activity level\n",
    "        'success': election['ElectionSuccess']\n",
    "    }\n",
    "\n",
    "# Converting the dictionary to a DataFrame for easier analysis\n",
    "elections_df = pd.DataFrame.from_dict(election_centralities, orient='index')\n",
    "\n",
    "# Splitting data into successful and unsuccessful elections\n",
    "successful = elections_df[elections_df['success'] == 1]\n",
    "unsuccessful = elections_df[elections_df['success'] == 0]\n",
    "\n",
    "# Performing t-tests for each centrality measure and activity metrics\n",
    "results_degree = ttest_ind(successful['avg_degree'], unsuccessful['avg_degree'], equal_var=False)\n",
    "results_closeness = ttest_ind(successful['avg_closeness'], unsuccessful['avg_closeness'], equal_var=False)\n",
    "results_betweenness = ttest_ind(successful['avg_betweenness'], unsuccessful['avg_betweenness'], equal_var=False)\n",
    "results_activity = ttest_ind(successful['avg_activity'], unsuccessful['avg_activity'], equal_var=False)\n",
    "\n",
    "# Printing the results for all metrics\n",
    "print(\"T-test results for Degree Centrality:\", results_degree)\n",
    "print(\"T-test results for Closeness Centrality:\", results_closeness)\n",
    "print(\"T-test results for Betweenness Centrality:\", results_betweenness)\n",
    "print(\"T-test results for Voter Activity Level:\", results_activity)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
